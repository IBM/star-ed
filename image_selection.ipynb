{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heavy-humor",
   "metadata": {},
   "source": [
    "## Document Convertion, Image Extraction and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-repeat",
   "metadata": {},
   "source": [
    "### Document Convertion\n",
    "To use deepsearch to convert documents to json files to extract images is needed to register [here](https://ds4sd.github.io/deepsearch-toolkit/guide/configuration/) and run:\n",
    "\n",
    "`$ deepsearch profile config\n",
    "Host: https://deepsearch-experience.res.ibm.com\n",
    "Username: name@example.com\n",
    "Api key:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepsearch as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsearch.cps.client.api import CpsApi\n",
    "\n",
    "api = CpsApi.from_env()\n",
    "print([(p.name, p.key) for p in api.projects.list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DOCS = \"PATH OR LINK TO PDF.pdf\"\"\n",
    "PROJ_KEY = \"\"\n",
    "RESULT_DIR = \"PATH TO OUTPUT FOLDER\"\n",
    "\n",
    "# for online documents use urls= and for local files use source_path\n",
    "documents = ds.convert_documents(api=api, proj_key=PROJ_KEY, urls=PATH_DOCS)\n",
    "\n",
    "documents.download_all(result_dir=RESULT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-poster",
   "metadata": {},
   "source": [
    "this cell will return a json file with information regarding the extraction output of the submissted pdf, the \"figures\" section is the one that we will use to extract the images that we're interested in with bbox information\n",
    "\n",
    "`{\"_name\": \"s41746-023-00881-0.pdf\", \"_type\": \"pdf-document\", ...,  \"figures\": [{\"bounding-box\": {\"max\": [6.9888954, 241.64507, 595.276, 734.6084], \"min\": [47.72477340698242, 243.7888793945312, 555.028564453125, 733.34814453125]}, \"cells\": {\"data\": [], \"header\": [\"x0\", \"y0\", \"x1\", \"y1\", \"font\", \"text\"]}, \"confidence\": 0.865432858467102, \"created_by\": \"high_conf_pred\", \"prov\": [{\"bbox\": [47.72477340698242, 243.7888793945312, 555.028564453125, 733.34814453125], \"page\": 2, \"span\": [0, 0]}], ....`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-jonathan",
   "metadata": {},
   "source": [
    "### Image Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neutral-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "\n",
    "class PdfFileWriterWithStreamAttribute(PdfWriter):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        from io import BytesIO\n",
    "\n",
    "        self.stream = BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "JSON_FILE = \"PATH TO JSON.json\"\n",
    "PDF_FILE = \"PATH TO PDF.pdf\"\n",
    "CROP_DIR = \"PATH TO SAVE CROPPED IMAGES FOLDER\"\n",
    "\n",
    "jsonFile = open(JSON_FILE)\n",
    "jsonData = json.load(jsonFile)\n",
    "jsonFile.close()\n",
    "figures = jsonData[\"figures\"]  # use directories for multiple pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-money",
   "metadata": {},
   "source": [
    "Looks for bounding boxes and exports individual files per each figure found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(PDF_FILE, \"r\")\n",
    "if os.path.exists(JSON_FILE):\n",
    "    with open(JSON_FILE) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    for image_num in range(len(figures) - 1):\n",
    "        cors = data[\"figures\"][image_num][\"prov\"][0][\"bbox\"]\n",
    "        page_num = data[\"figures\"][image_num][\"prov\"][0][\"page\"] - 1\n",
    "        page = reader.pages[page_num]\n",
    "        writer = PdfFileWriterWithStreamAttribute()\n",
    "        page.cropbox.upper_right = (cors[2], cors[3])\n",
    "        page.cropbox.lower_left = (cors[0], cors[1])\n",
    "        writer.add_page(page)\n",
    "        outstream = open(\n",
    "            os.path.join(\n",
    "                CROP_DIR,\n",
    "                os.path.split(PDF_FILE)[-1].split(\".pdf\")[0]\n",
    "                + \"_cropped_page_\"\n",
    "                + str(page_num + 1)\n",
    "                + \".pdf\",\n",
    "            ),\n",
    "            \"wb\",\n",
    "        )\n",
    "        writer.write(outstream)\n",
    "        outstream.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
